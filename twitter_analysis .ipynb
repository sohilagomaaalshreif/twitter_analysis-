{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "name": "twitter-analysis.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3xlW096tw3zn",
        "colab_type": "text"
      },
      "source": [
        "# Twitter analysis \n",
        "\n",
        "<center><img src=\"https://techcrunch.com/wp-content/uploads/2017/12/gettyimages-876768474.jpg?w=730&crop=1\"></center>\n",
        "\n",
        "Analyze the sentiment of tweets on some query search, your model should learn from [this dataset](https://www.kaggle.com/kazanova/sentiment140)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxBteYZsqpSo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "77eac035-a4f9-4bf8-bf38-6acfb8d51740"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-02-22T14:46:02.193851Z",
          "start_time": "2020-02-22T14:46:02.189856Z"
        },
        "id": "ofciS9xow3zr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "query = \"egypt\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9r4KVJCA0h-a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        },
        "outputId": "cdc44481-8008-45f1-d959-0a2b33cb3816"
      },
      "source": [
        "!pip install pydrive"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pydrive in /usr/local/lib/python3.6/dist-packages (1.3.1)\n",
            "Requirement already satisfied: google-api-python-client>=1.2 in /usr/local/lib/python3.6/dist-packages (from pydrive) (1.7.11)\n",
            "Requirement already satisfied: PyYAML>=3.0 in /usr/local/lib/python3.6/dist-packages (from pydrive) (3.13)\n",
            "Requirement already satisfied: oauth2client>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pydrive) (4.1.3)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.9.2 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->pydrive) (0.11.3)\n",
            "Requirement already satisfied: six<2dev,>=1.6.1 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->pydrive) (1.12.0)\n",
            "Requirement already satisfied: google-auth>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->pydrive) (1.7.2)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->pydrive) (0.0.3)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->pydrive) (3.0.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->pydrive) (0.2.8)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->pydrive) (4.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->pydrive) (0.4.8)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.4.1->google-api-python-client>=1.2->pydrive) (45.1.0)\n",
            "Requirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.4.1->google-api-python-client>=1.2->pydrive) (3.1.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nzCxgveZ0uuB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iRhmksQf0wHa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_HTnioHT1KsV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "downloaded = drive.CreateFile({'id':\"1CZtBvbjvUvEbVuFyMVGzmIkU1uFWv_RQ\"})   # replace the id with id of file you want to access\n",
        "downloaded.GetContentFile('Copy of training_twitter.csv') "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yXGEV7p-w3zw",
        "colab_type": "text"
      },
      "source": [
        "# Start by building your sentiment analysis classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-02-22T14:46:02.311744Z",
          "start_time": "2020-02-22T14:46:02.196848Z"
        },
        "id": "KVRoDUNpw3zx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import csv\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-02-22T14:46:10.258378Z",
          "start_time": "2020-02-22T14:46:02.314740Z"
        },
        "id": "Uz5uFJKVw3z1",
        "colab_type": "code",
        "outputId": "0405f5a8-dc84-4cf9-8bd1-30a9417b7ee2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "# reading the data\n",
        "cols = [\"Sentiment\",\"ID\",\"Date\",\"Query\",\"Username\",\"Tweet\"]\n",
        "dataset = pd.read_csv(\"Copy of training_twitter.csv\", encoding='latin-1',delimiter='\",\"',engine='python')\n",
        "dataset.head()"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>\"0</th>\n",
              "      <th>1467810369</th>\n",
              "      <th>Mon Apr 06 22:19:45 PDT 2009</th>\n",
              "      <th>NO_QUERY</th>\n",
              "      <th>_TheSpecialOne_</th>\n",
              "      <th>@switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D\"</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>\"0</td>\n",
              "      <td>1467810672</td>\n",
              "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>scotthamilton</td>\n",
              "      <td>is upset that he can't update his Facebook by ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\"0</td>\n",
              "      <td>1467810917</td>\n",
              "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>mattycus</td>\n",
              "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>\"0</td>\n",
              "      <td>1467811184</td>\n",
              "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>ElleCTF</td>\n",
              "      <td>my whole body feels itchy and like its on fire \"</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\"0</td>\n",
              "      <td>1467811193</td>\n",
              "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>Karoli</td>\n",
              "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>\"0</td>\n",
              "      <td>1467811372</td>\n",
              "      <td>Mon Apr 06 22:20:00 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>joy_wolf</td>\n",
              "      <td>@Kwesidei not the whole crew \"</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   \"0  ...  @switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D\"\n",
              "0  \"0  ...  is upset that he can't update his Facebook by ...                                                                   \n",
              "1  \"0  ...  @Kenichan I dived many times for the ball. Man...                                                                   \n",
              "2  \"0  ...   my whole body feels itchy and like its on fire \"                                                                   \n",
              "3  \"0  ...  @nationwideclass no, it's not behaving at all....                                                                   \n",
              "4  \"0  ...                     @Kwesidei not the whole crew \"                                                                   \n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LfYaAxdeaZKR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 606
        },
        "outputId": "c3982fe3-ce17-401a-8e3e-e2c1d3758cfe"
      },
      "source": [
        "from sklearn.utils import shuffle\n",
        "dataset = shuffle(dataset)\n",
        "dataset"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>\"0</th>\n",
              "      <th>1467810369</th>\n",
              "      <th>Mon Apr 06 22:19:45 PDT 2009</th>\n",
              "      <th>NO_QUERY</th>\n",
              "      <th>_TheSpecialOne_</th>\n",
              "      <th>@switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D\"</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>619288</th>\n",
              "      <td>\"0</td>\n",
              "      <td>2227865899</td>\n",
              "      <td>Thu Jun 18 13:43:49 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>RenovatioNow</td>\n",
              "      <td>Going this way is futile, i should have known ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>753838</th>\n",
              "      <td>\"0</td>\n",
              "      <td>2287022737</td>\n",
              "      <td>Mon Jun 22 17:14:46 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>starringSHORA</td>\n",
              "      <td>RIP laptop  no more computer for meee\"</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48840</th>\n",
              "      <td>\"0</td>\n",
              "      <td>1677977432</td>\n",
              "      <td>Sat May 02 04:57:21 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>misscee</td>\n",
              "      <td>@feliciatemple awwwww leesh... \"</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>152440</th>\n",
              "      <td>\"0</td>\n",
              "      <td>1932738216</td>\n",
              "      <td>Tue May 26 22:06:24 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>AnnaAtomic</td>\n",
              "      <td>im sick...  my head hurts really bad...\"</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3976</th>\n",
              "      <td>\"0</td>\n",
              "      <td>1468718005</td>\n",
              "      <td>Tue Apr 07 03:20:50 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>BabaMzungu</td>\n",
              "      <td>Postponing my trip to Kenya. G/F going to TZ f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>736082</th>\n",
              "      <td>\"0</td>\n",
              "      <td>2264932335</td>\n",
              "      <td>Sun Jun 21 05:20:47 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>xAbbysarahx</td>\n",
              "      <td>Time to revise \"</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>328460</th>\n",
              "      <td>\"0</td>\n",
              "      <td>2010609935</td>\n",
              "      <td>Tue Jun 02 17:40:16 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>emacdanico</td>\n",
              "      <td>@kaseyleboeuf i feel so hated \"</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>878414</th>\n",
              "      <td>\"4</td>\n",
              "      <td>1685239043</td>\n",
              "      <td>Sat May 02 23:34:32 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>clintlundie</td>\n",
              "      <td>should have said &amp;quot;tweeple&amp;quot;  \"</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1072135</th>\n",
              "      <td>\"4</td>\n",
              "      <td>1966502240</td>\n",
              "      <td>Fri May 29 17:53:08 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>JonGuiro</td>\n",
              "      <td>I finally joined the twitter network! Yay! Hi ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1184728</th>\n",
              "      <td>\"4</td>\n",
              "      <td>1982651564</td>\n",
              "      <td>Sun May 31 11:38:02 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>BDDesign</td>\n",
              "      <td>good morning bitches... \"</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1599999 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         \"0  ...  @switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D\"\n",
              "619288   \"0  ...  Going this way is futile, i should have known ...                                                                   \n",
              "753838   \"0  ...             RIP laptop  no more computer for meee\"                                                                   \n",
              "48840    \"0  ...                   @feliciatemple awwwww leesh... \"                                                                   \n",
              "152440   \"0  ...           im sick...  my head hurts really bad...\"                                                                   \n",
              "3976     \"0  ...  Postponing my trip to Kenya. G/F going to TZ f...                                                                   \n",
              "...      ..  ...                                                ...                                                                   \n",
              "736082   \"0  ...                                   Time to revise \"                                                                   \n",
              "328460   \"0  ...                    @kaseyleboeuf i feel so hated \"                                                                   \n",
              "878414   \"4  ...            should have said &quot;tweeple&quot;  \"                                                                   \n",
              "1072135  \"4  ...  I finally joined the twitter network! Yay! Hi ...                                                                   \n",
              "1184728  \"4  ...                          good morning bitches... \"                                                                   \n",
              "\n",
              "[1599999 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-02-22T14:46:10.638027Z",
          "start_time": "2020-02-22T14:46:10.262375Z"
        },
        "id": "1u_EBTbqw3z7",
        "colab_type": "code",
        "outputId": "24cfd866-49b6-402b-a1d2-a641b169f23b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "dataset = dataset.iloc[:500000,:]\n",
        "dataset.columns = [\"Sentiment\",\"ID\",\"Date\",\"Query\",\"Username\",\"Tweet\"]\n",
        "dataset['Sentiment'] = dataset['Sentiment'].apply(lambda x: int(x[1:]))\n",
        "dataset.info()"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 500000 entries, 619288 to 259418\n",
            "Data columns (total 6 columns):\n",
            "Sentiment    500000 non-null int64\n",
            "ID           500000 non-null int64\n",
            "Date         500000 non-null object\n",
            "Query        500000 non-null object\n",
            "Username     500000 non-null object\n",
            "Tweet        500000 non-null object\n",
            "dtypes: int64(2), object(4)\n",
            "memory usage: 26.7+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-02-22T14:46:10.650017Z",
          "start_time": "2020-02-22T14:46:10.641024Z"
        },
        "id": "MtGKbeJlw30A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def check_for_word(text):\n",
        "    if query in text:\n",
        "        return text\n",
        "    else:\n",
        "        return None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-02-22T14:46:11.090608Z",
          "start_time": "2020-02-22T14:46:10.658008Z"
        },
        "id": "qurWejK3w30E",
        "colab_type": "code",
        "outputId": "ed9d0fe6-19b1-46ae-be2f-5506a8e0b8d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "features = dataset.drop(columns=[\"ID\",\"Date\",\"Query\",\"Username\"])\n",
        "features[\"Tweet\"] = features[\"Tweet\"]\n",
        "goal = features[\"Sentiment\"]\n",
        "features = features.drop(columns=[\"Sentiment\"])\n",
        "features.info()"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 500000 entries, 619288 to 259418\n",
            "Data columns (total 1 columns):\n",
            "Tweet    500000 non-null object\n",
            "dtypes: object(1)\n",
            "memory usage: 7.6+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-02-22T14:46:11.100597Z",
          "start_time": "2020-02-22T14:46:11.093605Z"
        },
        "id": "yOfoIlArw30L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "def normalize_text(text):\n",
        "    \n",
        "    # reduce all to lower case\n",
        "    text = str(text).strip().lower()\n",
        "    \n",
        "    # remove non-alpha characters\n",
        "    text = re.sub(r\"[^a-z]\", \" \", text)\n",
        "    \n",
        "    return text.strip()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-02-22T14:46:26.817100Z",
          "start_time": "2020-02-22T14:46:11.104595Z"
        },
        "id": "Ll0roJ1iw30V",
        "colab_type": "code",
        "outputId": "55ac3c56-f571-49b6-faa7-53a0b6845ef4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-02-22T14:46:26.878042Z",
          "start_time": "2020-02-22T14:46:26.821097Z"
        },
        "id": "N0k8Qdpqw30d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "stemmer = PorterStemmer()\n",
        "def stemming_text(text):\n",
        "    words = text.split()\n",
        "    words = [stemmer.stem(word.strip()) for word in words]\n",
        "    return \" \".join(words)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-02-22T14:46:26.970955Z",
          "start_time": "2020-02-22T14:46:26.881039Z"
        },
        "id": "3hPsunS4w30h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "def lemm_text(text):\n",
        "    words = text.split()\n",
        "    words = [lemmatizer.lemmatize(word, pos='v') for word in words]\n",
        "    return \" \".join(words)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-02-22T14:56:01.153920Z",
          "start_time": "2020-02-22T14:46:26.972953Z"
        },
        "cell_style": "center",
        "id": "haliHAcpw30l",
        "colab_type": "code",
        "outputId": "0d4e295c-be01-41c6-c9eb-a6dc3e543841",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "features[\"Tweet\"] = features[\"Tweet\"].apply(normalize_text)\n",
        "features[\"Tweet\"] = features[\"Tweet\"].apply(stemming_text)\n",
        "features[\"Tweet\"] = features[\"Tweet\"].apply(lemm_text)\n",
        "\n",
        "features"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>619288</th>\n",
              "      <td>go thi way be futil i should have know better ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>753838</th>\n",
              "      <td>rip laptop no more comput for meee</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48840</th>\n",
              "      <td>feliciatempl awwwww leesh</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>152440</th>\n",
              "      <td>im sick my head hurt realli bad</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3976</th>\n",
              "      <td>postpon my trip to kenya g f go to tz for trai...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1398791</th>\n",
              "      <td>my new shoe make my leave foot stick out more ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>320542</th>\n",
              "      <td>some quick shutey on the train but now my mood...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1486053</th>\n",
              "      <td>out mahh sistaa cookout new jersey awww gonna ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1401664</th>\n",
              "      <td>watch into the wood</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>259418</th>\n",
              "      <td>realli sunburn</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>500000 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                     Tweet\n",
              "619288   go thi way be futil i should have know better ...\n",
              "753838                  rip laptop no more comput for meee\n",
              "48840                            feliciatempl awwwww leesh\n",
              "152440                     im sick my head hurt realli bad\n",
              "3976     postpon my trip to kenya g f go to tz for trai...\n",
              "...                                                    ...\n",
              "1398791  my new shoe make my leave foot stick out more ...\n",
              "320542   some quick shutey on the train but now my mood...\n",
              "1486053  out mahh sistaa cookout new jersey awww gonna ...\n",
              "1401664                                watch into the wood\n",
              "259418                                      realli sunburn\n",
              "\n",
              "[500000 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-02-22T14:57:32.493585Z",
          "start_time": "2020-02-22T14:56:01.155919Z"
        },
        "id": "wHFKXUZ3w30p",
        "colab_type": "code",
        "outputId": "aebaafee-4b33-4cf0-fa97-8746d0c3c115",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        }
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "vectorizer = TfidfVectorizer(stop_words='english', max_features=2000, min_df=20)\n",
        "\n",
        "vectorizer.fit(features[\"Tweet\"])\n",
        "\n",
        "features = vectorizer.transform(features[\"Tweet\"])\n",
        "\n",
        "features = pd.DataFrame(\n",
        "    features.astype(np.int32).toarray(), columns=vectorizer.get_feature_names())\n",
        "features.head()"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>abl</th>\n",
              "      <th>absolut</th>\n",
              "      <th>abt</th>\n",
              "      <th>ac</th>\n",
              "      <th>accept</th>\n",
              "      <th>access</th>\n",
              "      <th>accid</th>\n",
              "      <th>account</th>\n",
              "      <th>ace</th>\n",
              "      <th>ach</th>\n",
              "      <th>act</th>\n",
              "      <th>action</th>\n",
              "      <th>activ</th>\n",
              "      <th>actual</th>\n",
              "      <th>ad</th>\n",
              "      <th>adam</th>\n",
              "      <th>add</th>\n",
              "      <th>addict</th>\n",
              "      <th>address</th>\n",
              "      <th>admit</th>\n",
              "      <th>ador</th>\n",
              "      <th>adventur</th>\n",
              "      <th>advic</th>\n",
              "      <th>afford</th>\n",
              "      <th>afraid</th>\n",
              "      <th>afternoon</th>\n",
              "      <th>age</th>\n",
              "      <th>ago</th>\n",
              "      <th>agre</th>\n",
              "      <th>ah</th>\n",
              "      <th>aha</th>\n",
              "      <th>ahaha</th>\n",
              "      <th>ahead</th>\n",
              "      <th>ahh</th>\n",
              "      <th>ahhh</th>\n",
              "      <th>ahhhh</th>\n",
              "      <th>aim</th>\n",
              "      <th>ain</th>\n",
              "      <th>aint</th>\n",
              "      <th>air</th>\n",
              "      <th>...</th>\n",
              "      <th>wouldn</th>\n",
              "      <th>wouldnt</th>\n",
              "      <th>wow</th>\n",
              "      <th>wrap</th>\n",
              "      <th>write</th>\n",
              "      <th>wrong</th>\n",
              "      <th>wtf</th>\n",
              "      <th>www</th>\n",
              "      <th>xbox</th>\n",
              "      <th>xd</th>\n",
              "      <th>xo</th>\n",
              "      <th>xoxo</th>\n",
              "      <th>xx</th>\n",
              "      <th>xxx</th>\n",
              "      <th>xxxx</th>\n",
              "      <th>ya</th>\n",
              "      <th>yah</th>\n",
              "      <th>yall</th>\n",
              "      <th>yard</th>\n",
              "      <th>yay</th>\n",
              "      <th>ye</th>\n",
              "      <th>yea</th>\n",
              "      <th>yeah</th>\n",
              "      <th>year</th>\n",
              "      <th>yeh</th>\n",
              "      <th>yell</th>\n",
              "      <th>yep</th>\n",
              "      <th>yesterday</th>\n",
              "      <th>yey</th>\n",
              "      <th>yfrog</th>\n",
              "      <th>yo</th>\n",
              "      <th>york</th>\n",
              "      <th>young</th>\n",
              "      <th>youtub</th>\n",
              "      <th>youu</th>\n",
              "      <th>yr</th>\n",
              "      <th>yu</th>\n",
              "      <th>yum</th>\n",
              "      <th>yummi</th>\n",
              "      <th>yup</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 2000 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   abl  absolut  abt  ac  accept  access  ...  youu  yr  yu  yum  yummi  yup\n",
              "0    0        0    0   0       0       0  ...     0   0   0    0      0    0\n",
              "1    0        0    0   0       0       0  ...     0   0   0    0      0    0\n",
              "2    0        0    0   0       0       0  ...     0   0   0    0      0    0\n",
              "3    0        0    0   0       0       0  ...     0   0   0    0      0    0\n",
              "4    0        0    0   0       0       0  ...     0   0   0    0      0    0\n",
              "\n",
              "[5 rows x 2000 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-02-22T15:00:51.829163Z",
          "start_time": "2020-02-22T15:00:51.116825Z"
        },
        "id": "mLOyeluhw30t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(features, goal,test_size=0.1, random_state = 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-02-22T15:00:52.704353Z",
          "start_time": "2020-02-22T15:00:52.671382Z"
        },
        "id": "gayp4tvVw30z",
        "colab_type": "code",
        "outputId": "cb513b08-8fd2-4ba4-fa8f-b1f26a0464d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 799
        }
      },
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "\n",
        "# clf1 = LogisticRegression(random_state=1)\n",
        "clf2 = LinearSVC(random_state=1)\n",
        "clf3 = GaussianNB()\n",
        "clf4 = MultinomialNB()\n",
        "# clf5 = DecisionTreeClassifier(max_depth=4)\n",
        "# clf6 = KNeighborsClassifier(n_neighbors=10)\n",
        "# clf7 = SVC(kernel='rbf', probability=True)\n",
        "\n",
        "# eclf = VotingClassifier(estimators=[('lr', clf1), ('svc', clf2), ('gnb', clf3) , ('mnb', clf4) , ('dt', clf5) , ('knn', clf6) , ('svc', clf7)], voting='hard')\n",
        "eclf = VotingClassifier(estimators=[('svc', clf2),('mnb', clf4), ('gnb', clf3) ], voting='hard')\n",
        "\n",
        "for classifier in [clf3 , clf4 , eclf]:\n",
        "  classifier.fit(x_train, y_train)\n",
        "  y_pred = classifier.predict(x_test)\n",
        "  print(classifier.score(x_test,y_test))\n",
        "  print(str(classifier))\n",
        "  print(classification_report(y_test, y_pred))"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.5192\n",
            "GaussianNB(priors=None, var_smoothing=1e-09)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.51      0.98      0.67     25039\n",
            "           4       0.76      0.05      0.10     24961\n",
            "\n",
            "    accuracy                           0.52     50000\n",
            "   macro avg       0.63      0.52      0.39     50000\n",
            "weighted avg       0.63      0.52      0.39     50000\n",
            "\n",
            "0.51332\n",
            "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.04      0.08     25039\n",
            "           4       0.51      0.98      0.67     24961\n",
            "\n",
            "    accuracy                           0.51     50000\n",
            "   macro avg       0.62      0.51      0.38     50000\n",
            "weighted avg       0.62      0.51      0.38     50000\n",
            "\n",
            "0.51948\n",
            "VotingClassifier(estimators=[('svc',\n",
            "                              LinearSVC(C=1.0, class_weight=None, dual=True,\n",
            "                                        fit_intercept=True, intercept_scaling=1,\n",
            "                                        loss='squared_hinge', max_iter=1000,\n",
            "                                        multi_class='ovr', penalty='l2',\n",
            "                                        random_state=1, tol=0.0001,\n",
            "                                        verbose=0)),\n",
            "                             ('mnb',\n",
            "                              MultinomialNB(alpha=1.0, class_prior=None,\n",
            "                                            fit_prior=True)),\n",
            "                             ('gnb',\n",
            "                              GaussianNB(priors=None, var_smoothing=1e-09))],\n",
            "                 flatten_transform=True, n_jobs=None, voting='hard',\n",
            "                 weights=None)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.51      0.98      0.67     25039\n",
            "           4       0.75      0.06      0.10     24961\n",
            "\n",
            "    accuracy                           0.52     50000\n",
            "   macro avg       0.63      0.52      0.39     50000\n",
            "weighted avg       0.63      0.52      0.39     50000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fBx79azZw305",
        "colab_type": "text"
      },
      "source": [
        "# Now time to collect some tweets based on the given query\n",
        "\n",
        "for this task you can use multiple libraries, one of the very best ones is [twitterscraper by taspinar](https://github.com/taspinar/twitterscraper)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQ8e8_rdU03r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "outputId": "b39f5889-e9ee-47a8-82ce-74fdc37e7ea7"
      },
      "source": [
        "!pip install twitterscraper"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting twitterscraper\n",
            "  Downloading https://files.pythonhosted.org/packages/7f/0f/7cf31233d4f5616c971f6b1ae22dd73fe9a69430877f5c37a0e7b508a311/twitterscraper-1.4.0.tar.gz\n",
            "Collecting coala-utils~=0.5.0\n",
            "  Downloading https://files.pythonhosted.org/packages/54/00/74ec750cfc4e830f9d1cfdd4d559f3d2d4ba1b834b78d5266446db3fd1d6/coala_utils-0.5.1-py3-none-any.whl\n",
            "Requirement already satisfied: bs4 in /usr/local/lib/python3.6/dist-packages (from twitterscraper) (0.0.1)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.6/dist-packages (from twitterscraper) (4.2.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from twitterscraper) (2.21.0)\n",
            "Collecting billiard\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e8/5e/7591866ff45b370354bd20291cb6f87ddb2eef1f1c88c890a38412037e11/billiard-3.6.3.0-py3-none-any.whl (89kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 3.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.6/dist-packages (from bs4->twitterscraper) (4.6.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->twitterscraper) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->twitterscraper) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->twitterscraper) (2019.11.28)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->twitterscraper) (2.8)\n",
            "Building wheels for collected packages: twitterscraper\n",
            "  Building wheel for twitterscraper (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for twitterscraper: filename=twitterscraper-1.4.0-cp36-none-any.whl size=11347 sha256=18e07bc75af7ba9096a9e38e80818f3537f6b0700141cce5cc44255de3b5140c\n",
            "  Stored in directory: /root/.cache/pip/wheels/c2/9c/8b/7393e7bdc8abe6ce0d46c2ffae2035a1a2080a97ff0ddbdde6\n",
            "Successfully built twitterscraper\n",
            "Installing collected packages: coala-utils, billiard, twitterscraper\n",
            "Successfully installed billiard-3.6.3.0 coala-utils-0.5.1 twitterscraper-1.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-02-22T14:57:45.706340Z",
          "start_time": "2020-02-22T14:46:02.238Z"
        },
        "id": "QVIC2Pulw306",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8a551964-9052-461c-ea46-f98c8c7cecd5"
      },
      "source": [
        "from twitterscraper import query_tweets"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO: {'User-Agent': 'Mozilla/5.0 (compatible, MSIE 11, Windows NT 6.3; Trident/7.0; rv:11.0) like Gecko'}\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-02-22T14:57:45.708336Z",
          "start_time": "2020-02-22T14:46:02.243Z"
        },
        "id": "TZWYkhzOw30-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "fb095024-b0d0-4d67-f472-ed038953fdee"
      },
      "source": [
        "TestTweets = pd.DataFrame(columns=[\"Tweets\"])\n",
        "for index,tweet in enumerate(query_tweets(\"coronavirus\", 20)[:20]):\n",
        "    TestTweets.loc[index,'Tweets'] = tweet.text.encode('utf-8')[2:]\n",
        "    print(tweet.text.encode('utf-8')[2:])"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO: queries: ['coronavirus since:2006-03-21 until:2006-11-30', 'coronavirus since:2006-11-30 until:2007-08-12', 'coronavirus since:2007-08-12 until:2008-04-22', 'coronavirus since:2008-04-22 until:2009-01-02', 'coronavirus since:2009-01-02 until:2009-09-13', 'coronavirus since:2009-09-13 until:2010-05-26', 'coronavirus since:2010-05-26 until:2011-02-04', 'coronavirus since:2011-02-04 until:2011-10-17', 'coronavirus since:2011-10-17 until:2012-06-27', 'coronavirus since:2012-06-27 until:2013-03-09', 'coronavirus since:2013-03-09 until:2013-11-19', 'coronavirus since:2013-11-19 until:2014-07-31', 'coronavirus since:2014-07-31 until:2015-04-12', 'coronavirus since:2015-04-12 until:2015-12-22', 'coronavirus since:2015-12-22 until:2016-09-02', 'coronavirus since:2016-09-02 until:2017-05-14', 'coronavirus since:2017-05-14 until:2018-01-24', 'coronavirus since:2018-01-24 until:2018-10-05', 'coronavirus since:2018-10-05 until:2019-06-17', 'coronavirus since:2019-06-17 until:2020-02-27']\n",
            "INFO: Querying coronavirus since:2006-03-21 until:2006-11-30\n",
            "INFO: Querying coronavirus since:2006-11-30 until:2007-08-12\n",
            "INFO: Querying coronavirus since:2008-04-22 until:2009-01-02\n",
            "INFO: Querying coronavirus since:2007-08-12 until:2008-04-22\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=coronavirus%20since%3A2006-03-21%20until%3A2006-11-30&l=\n",
            "INFO: Using proxy 200.89.178.231:8080\n",
            "INFO: Querying coronavirus since:2011-02-04 until:2011-10-17\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=coronavirus%20since%3A2011-02-04%20until%3A2011-10-17&l=\n",
            "INFO: Using proxy 200.89.178.231:8080\n",
            "INFO: Querying coronavirus since:2011-10-17 until:2012-06-27\n",
            "INFO: Querying coronavirus since:2016-09-02 until:2017-05-14\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=coronavirus%20since%3A2006-11-30%20until%3A2007-08-12&l=\n",
            "INFO: Querying coronavirus since:2010-05-26 until:2011-02-04\n",
            "INFO: Querying coronavirus since:2013-03-09 until:2013-11-19\n",
            "INFO: Querying coronavirus since:2012-06-27 until:2013-03-09\n",
            "INFO: Using proxy 200.89.178.231:8080\n",
            "INFO: Querying coronavirus since:2015-12-22 until:2016-09-02\n",
            "INFO: Querying coronavirus since:2017-05-14 until:2018-01-24\n",
            "INFO: Querying coronavirus since:2013-11-19 until:2014-07-31\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=coronavirus%20since%3A2012-06-27%20until%3A2013-03-09&l=\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=coronavirus%20since%3A2013-03-09%20until%3A2013-11-19&l=\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=coronavirus%20since%3A2015-12-22%20until%3A2016-09-02&l=\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=coronavirus%20since%3A2016-09-02%20until%3A2017-05-14&l=\n",
            "INFO: Using proxy 200.89.178.231:8080\n",
            "INFO: Using proxy 200.89.178.231:8080\n",
            "INFO: Querying coronavirus since:2014-07-31 until:2015-04-12\n",
            "INFO: Querying coronavirus since:2015-04-12 until:2015-12-22\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=coronavirus%20since%3A2011-10-17%20until%3A2012-06-27&l=\n",
            "INFO: Querying coronavirus since:2009-01-02 until:2009-09-13\n",
            "INFO: Querying coronavirus since:2018-10-05 until:2019-06-17\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=coronavirus%20since%3A2010-05-26%20until%3A2011-02-04&l=\n",
            "INFO: Using proxy 200.89.178.231:8080\n",
            "INFO: Querying coronavirus since:2018-01-24 until:2018-10-05\n",
            "INFO: Querying coronavirus since:2009-09-13 until:2010-05-26\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=coronavirus%20since%3A2017-05-14%20until%3A2018-01-24&l=\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=coronavirus%20since%3A2013-11-19%20until%3A2014-07-31&l=\n",
            "INFO: Using proxy 200.89.178.231:8080\n",
            "INFO: Using proxy 200.89.178.231:8080\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=coronavirus%20since%3A2009-09-13%20until%3A2010-05-26&l=\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=coronavirus%20since%3A2009-01-02%20until%3A2009-09-13&l=\n",
            "INFO: Querying coronavirus since:2019-06-17 until:2020-02-27\n",
            "INFO: Using proxy 200.89.178.231:8080\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=coronavirus%20since%3A2007-08-12%20until%3A2008-04-22&l=\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=coronavirus%20since%3A2008-04-22%20until%3A2009-01-02&l=\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=coronavirus%20since%3A2015-04-12%20until%3A2015-12-22&l=\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=coronavirus%20since%3A2018-01-24%20until%3A2018-10-05&l=\n",
            "INFO: Using proxy 200.89.178.231:8080\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=coronavirus%20since%3A2014-07-31%20until%3A2015-04-12&l=\n",
            "INFO: Using proxy 200.89.178.231:8080\n",
            "INFO: Using proxy 200.89.178.231:8080\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=coronavirus%20since%3A2019-06-17%20until%3A2020-02-27&l=\n",
            "INFO: Using proxy 200.89.178.231:8080\n",
            "INFO: Using proxy 200.89.178.231:8080\n",
            "INFO: Using proxy 200.89.178.231:8080\n",
            "INFO: Using proxy 200.89.178.231:8080\n",
            "INFO: Using proxy 200.89.178.231:8080\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=coronavirus%20since%3A2018-10-05%20until%3A2019-06-17&l=\n",
            "INFO: Using proxy 200.89.178.231:8080\n",
            "INFO: Using proxy 200.89.178.231:8080\n",
            "INFO: Using proxy 200.89.178.231:8080\n",
            "INFO: Retrying... (Attempts left: 50)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=coronavirus%20since%3A2006-03-21%20until%3A2006-11-30&l=\n",
            "INFO: Using proxy 85.10.219.103:1080\n",
            "INFO: Scraping tweets from https://twitter.com/i/search/timeline?f=tweets&vertical=default&include_available_features=1&include_entities=1&reset_error_state=false&src=typd&max_position=TWEET-26311841-26311841&q=coronavirus%20since%3A2006-11-30%20until%3A2007-08-12&l=\n",
            "INFO: Using proxy 85.10.219.103:1080\n",
            "INFO: Got 2 tweets for coronavirus%20since%3A2006-11-30%20until%3A2007-08-12.\n",
            "INFO: Got 2 tweets (2 new).\n",
            "INFO: Got 4 tweets for coronavirus%20since%3A2007-08-12%20until%3A2008-04-22.\n",
            "INFO: Got 6 tweets (4 new).\n",
            "INFO: Got 9 tweets for coronavirus%20since%3A2008-04-22%20until%3A2009-01-02.\n",
            "INFO: Got 15 tweets (9 new).\n",
            "INFO: Retrying... (Attempts left: 49)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=coronavirus%20since%3A2006-03-21%20until%3A2006-11-30&l=\n",
            "INFO: Using proxy 190.103.179.6:8118\n",
            "INFO: Got 20 tweets for coronavirus%20since%3A2010-05-26%20until%3A2011-02-04.\n",
            "INFO: Got 35 tweets (20 new).\n",
            "INFO: Got 19 tweets for coronavirus%20since%3A2009-01-02%20until%3A2009-09-13.\n",
            "INFO: Got 54 tweets (19 new).\n",
            "INFO: Got 20 tweets for coronavirus%20since%3A2011-10-17%20until%3A2012-06-27.\n",
            "INFO: Got 74 tweets (20 new).\n",
            "INFO: Got 19 tweets for coronavirus%20since%3A2011-02-04%20until%3A2011-10-17.\n",
            "INFO: Got 93 tweets (19 new).\n",
            "INFO: Got 20 tweets for coronavirus%20since%3A2015-12-22%20until%3A2016-09-02.\n",
            "INFO: Got 113 tweets (20 new).\n",
            "INFO: Got 20 tweets for coronavirus%20since%3A2013-03-09%20until%3A2013-11-19.\n",
            "INFO: Got 19 tweets for coronavirus%20since%3A2016-09-02%20until%3A2017-05-14.\n",
            "INFO: Got 133 tweets (20 new).\n",
            "INFO: Got 152 tweets (19 new).\n",
            "INFO: Got 20 tweets for coronavirus%20since%3A2013-11-19%20until%3A2014-07-31.\n",
            "INFO: Got 19 tweets for coronavirus%20since%3A2018-10-05%20until%3A2019-06-17.\n",
            "INFO: Got 172 tweets (20 new).\n",
            "INFO: Got 191 tweets (19 new).\n",
            "INFO: Got 20 tweets for coronavirus%20since%3A2012-06-27%20until%3A2013-03-09.\n",
            "INFO: Got 211 tweets (20 new).\n",
            "INFO: Got 19 tweets for coronavirus%20since%3A2015-04-12%20until%3A2015-12-22.\n",
            "INFO: Got 230 tweets (19 new).\n",
            "INFO: Got 19 tweets for coronavirus%20since%3A2009-09-13%20until%3A2010-05-26.\n",
            "INFO: Got 249 tweets (19 new).\n",
            "INFO: Got 20 tweets for coronavirus%20since%3A2014-07-31%20until%3A2015-04-12.\n",
            "INFO: Got 20 tweets for coronavirus%20since%3A2018-01-24%20until%3A2018-10-05.\n",
            "INFO: Retrying... (Attempts left: 48)\n",
            "INFO: Got 269 tweets (20 new).\n",
            "INFO: Got 289 tweets (20 new).\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=coronavirus%20since%3A2006-03-21%20until%3A2006-11-30&l=\n",
            "INFO: Got 17 tweets for coronavirus%20since%3A2017-05-14%20until%3A2018-01-24.\n",
            "INFO: Using proxy 88.198.50.103:8080\n",
            "INFO: Got 306 tweets (17 new).\n",
            "INFO: Got 20 tweets for coronavirus%20since%3A2019-06-17%20until%3A2020-02-27.\n",
            "INFO: Got 326 tweets (20 new).\n",
            "INFO: Retrying... (Attempts left: 47)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=coronavirus%20since%3A2006-03-21%20until%3A2006-11-30&l=\n",
            "INFO: Using proxy 190.104.255.9:8080\n",
            "INFO: Retrying... (Attempts left: 46)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=coronavirus%20since%3A2006-03-21%20until%3A2006-11-30&l=\n",
            "INFO: Using proxy 157.230.21.212:8118\n",
            "INFO: Retrying... (Attempts left: 45)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=coronavirus%20since%3A2006-03-21%20until%3A2006-11-30&l=\n",
            "INFO: Using proxy 181.129.183.19:53281\n",
            "INFO: Retrying... (Attempts left: 44)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=coronavirus%20since%3A2006-03-21%20until%3A2006-11-30&l=\n",
            "INFO: Using proxy 103.221.254.102:31117\n",
            "INFO: Retrying... (Attempts left: 43)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=coronavirus%20since%3A2006-03-21%20until%3A2006-11-30&l=\n",
            "INFO: Using proxy 190.104.255.13:8080\n",
            "INFO: Retrying... (Attempts left: 42)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=coronavirus%20since%3A2006-03-21%20until%3A2006-11-30&l=\n",
            "INFO: Using proxy 186.159.3.193:41741\n",
            "INFO: Retrying... (Attempts left: 41)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=coronavirus%20since%3A2006-03-21%20until%3A2006-11-30&l=\n",
            "INFO: Using proxy 95.80.252.189:52371\n",
            "INFO: Retrying... (Attempts left: 40)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=coronavirus%20since%3A2006-03-21%20until%3A2006-11-30&l=\n",
            "INFO: Using proxy 138.99.109.38:37188\n",
            "INFO: Retrying... (Attempts left: 39)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=coronavirus%20since%3A2006-03-21%20until%3A2006-11-30&l=\n",
            "INFO: Using proxy 177.74.233.138:34756\n",
            "INFO: Retrying... (Attempts left: 38)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=coronavirus%20since%3A2006-03-21%20until%3A2006-11-30&l=\n",
            "INFO: Using proxy 201.204.46.10:39371\n",
            "INFO: Retrying... (Attempts left: 37)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=coronavirus%20since%3A2006-03-21%20until%3A2006-11-30&l=\n",
            "INFO: Using proxy 83.228.74.251:32384\n",
            "INFO: Retrying... (Attempts left: 36)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=coronavirus%20since%3A2006-03-21%20until%3A2006-11-30&l=\n",
            "INFO: Using proxy 177.128.42.25:50041\n",
            "INFO: Retrying... (Attempts left: 35)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=coronavirus%20since%3A2006-03-21%20until%3A2006-11-30&l=\n",
            "INFO: Using proxy 85.196.147.146:55527\n",
            "INFO: Retrying... (Attempts left: 34)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=coronavirus%20since%3A2006-03-21%20until%3A2006-11-30&l=\n",
            "INFO: Using proxy 64.225.111.34:8118\n",
            "INFO: Retrying... (Attempts left: 33)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=coronavirus%20since%3A2006-03-21%20until%3A2006-11-30&l=\n",
            "INFO: Using proxy 177.86.158.102:38500\n",
            "INFO: Retrying... (Attempts left: 32)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=coronavirus%20since%3A2006-03-21%20until%3A2006-11-30&l=\n",
            "INFO: Using proxy 94.130.125.221:1080\n",
            "INFO: Retrying... (Attempts left: 31)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=coronavirus%20since%3A2006-03-21%20until%3A2006-11-30&l=\n",
            "INFO: Using proxy 200.69.236.205:1080\n",
            "INFO: Retrying... (Attempts left: 30)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=coronavirus%20since%3A2006-03-21%20until%3A2006-11-30&l=\n",
            "INFO: Using proxy 169.57.157.146:8123\n",
            "INFO: Retrying... (Attempts left: 29)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=coronavirus%20since%3A2006-03-21%20until%3A2006-11-30&l=\n",
            "INFO: Using proxy 181.129.47.162:56022\n",
            "INFO: Retrying... (Attempts left: 28)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=coronavirus%20since%3A2006-03-21%20until%3A2006-11-30&l=\n",
            "INFO: Using proxy 200.25.254.193:54240\n",
            "INFO: Retrying... (Attempts left: 27)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=coronavirus%20since%3A2006-03-21%20until%3A2006-11-30&l=\n",
            "INFO: Using proxy 186.146.2.111:60837\n",
            "INFO: Retrying... (Attempts left: 26)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=coronavirus%20since%3A2006-03-21%20until%3A2006-11-30&l=\n",
            "INFO: Using proxy 203.202.245.58:80\n",
            "INFO: Retrying... (Attempts left: 25)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=coronavirus%20since%3A2006-03-21%20until%3A2006-11-30&l=\n",
            "INFO: Using proxy 169.57.157.148:80\n",
            "INFO: Retrying... (Attempts left: 24)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=coronavirus%20since%3A2006-03-21%20until%3A2006-11-30&l=\n",
            "INFO: Using proxy 88.102.13.246:39454\n",
            "INFO: Retrying... (Attempts left: 23)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=coronavirus%20since%3A2006-03-21%20until%3A2006-11-30&l=\n",
            "INFO: Using proxy 181.114.63.129:8085\n",
            "INFO: Retrying... (Attempts left: 22)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=coronavirus%20since%3A2006-03-21%20until%3A2006-11-30&l=\n",
            "INFO: Using proxy 187.44.167.78:60786\n",
            "INFO: Retrying... (Attempts left: 21)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=coronavirus%20since%3A2006-03-21%20until%3A2006-11-30&l=\n",
            "INFO: Using proxy 200.255.122.170:8080\n",
            "INFO: Retrying... (Attempts left: 20)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=coronavirus%20since%3A2006-03-21%20until%3A2006-11-30&l=\n",
            "INFO: Using proxy 103.239.254.114:30569\n",
            "INFO: Retrying... (Attempts left: 19)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=coronavirus%20since%3A2006-03-21%20until%3A2006-11-30&l=\n",
            "INFO: Using proxy 207.154.231.217:3128\n",
            "INFO: Retrying... (Attempts left: 18)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=coronavirus%20since%3A2006-03-21%20until%3A2006-11-30&l=\n",
            "INFO: Using proxy 200.73.128.196:3128\n",
            "INFO: Retrying... (Attempts left: 17)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=coronavirus%20since%3A2006-03-21%20until%3A2006-11-30&l=\n",
            "INFO: Using proxy 186.211.106.227:34334\n",
            "INFO: Retrying... (Attempts left: 16)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=coronavirus%20since%3A2006-03-21%20until%3A2006-11-30&l=\n",
            "INFO: Using proxy 138.197.157.45:8080\n",
            "INFO: Retrying... (Attempts left: 15)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=coronavirus%20since%3A2006-03-21%20until%3A2006-11-30&l=\n",
            "INFO: Using proxy 200.69.81.198:58593\n",
            "INFO: Retrying... (Attempts left: 14)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=coronavirus%20since%3A2006-03-21%20until%3A2006-11-30&l=\n",
            "INFO: Using proxy 177.66.53.117:46640\n",
            "INFO: Retrying... (Attempts left: 13)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=coronavirus%20since%3A2006-03-21%20until%3A2006-11-30&l=\n",
            "INFO: Using proxy 191.103.254.145:47324\n",
            "INFO: Retrying... (Attempts left: 12)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=coronavirus%20since%3A2006-03-21%20until%3A2006-11-30&l=\n",
            "INFO: Using proxy 144.217.103.67:8080\n",
            "INFO: Retrying... (Attempts left: 11)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=coronavirus%20since%3A2006-03-21%20until%3A2006-11-30&l=\n",
            "INFO: Using proxy 190.18.207.58:53281\n",
            "INFO: Retrying... (Attempts left: 10)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=coronavirus%20since%3A2006-03-21%20until%3A2006-11-30&l=\n",
            "INFO: Using proxy 94.228.21.66:30784\n",
            "INFO: Retrying... (Attempts left: 9)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=coronavirus%20since%3A2006-03-21%20until%3A2006-11-30&l=\n",
            "INFO: Using proxy 5.9.218.110:1080\n",
            "INFO: Retrying... (Attempts left: 8)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=coronavirus%20since%3A2006-03-21%20until%3A2006-11-30&l=\n",
            "INFO: Using proxy 68.183.76.24:8118\n",
            "INFO: Retrying... (Attempts left: 7)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=coronavirus%20since%3A2006-03-21%20until%3A2006-11-30&l=\n",
            "INFO: Using proxy 181.168.206.106:38024\n",
            "INFO: Retrying... (Attempts left: 6)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=coronavirus%20since%3A2006-03-21%20until%3A2006-11-30&l=\n",
            "INFO: Using proxy 91.67.240.32:3128\n",
            "INFO: Retrying... (Attempts left: 5)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=coronavirus%20since%3A2006-03-21%20until%3A2006-11-30&l=\n",
            "INFO: Using proxy 45.6.136.244:53281\n",
            "INFO: Retrying... (Attempts left: 4)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=coronavirus%20since%3A2006-03-21%20until%3A2006-11-30&l=\n",
            "INFO: Using proxy 150.242.34.116:53281\n",
            "INFO: Retrying... (Attempts left: 3)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=coronavirus%20since%3A2006-03-21%20until%3A2006-11-30&l=\n",
            "INFO: Using proxy 138.121.32.133:23492\n",
            "INFO: Retrying... (Attempts left: 2)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=coronavirus%20since%3A2006-03-21%20until%3A2006-11-30&l=\n",
            "INFO: Using proxy 187.4.201.134:8080\n",
            "INFO: Retrying... (Attempts left: 1)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=coronavirus%20since%3A2006-03-21%20until%3A2006-11-30&l=\n",
            "INFO: Using proxy 187.95.28.155:41475\n",
            "INFO: Got 0 tweets for coronavirus%20since%3A2006-03-21%20until%3A2006-11-30.\n",
            "INFO: Got 326 tweets (0 new).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "b' waiting for 3 10-page printouts on coronavirus for class tuesday. Hooray. Good work to both Karla and Kelly on respective bleeding stuff.'\n",
            "b' waiting for 3 10-page printouts on coronavirus for class tuesday. Hooray. Good work to both Karla and Kelly on respective bleeding stuff.'\n",
            "b'ishiness No not yet. Vet last yr said coz she was fighting the coronavirus it wud hav been 2 dangerous for her immune system to try.'\n",
            "b'rvously awaiting further test results from the vet. It will be 24 hours. They said the coronavirus titer was very high. :/'\n",
            "b'oks like she might hav a good fighting chance of recovery. Only 5% of cats with coronavirus develop FIP. Am feeling alot better abt it all'\n",
            "b\"st got a call from the vet. Ella has a viral infection called coronavirus. She can get better, only if it doesn't develop into the fat ...\"\n",
            "b'nine coronavirus S gene and uses therefor\\n[5013663]'\n",
            "b'oyaleagle Seen our coronavirus DB? http://lin.cr/7gq'\n",
            "b'scussing coronavirus (SARS) in virology class right now'\n",
            "b\"viewing an awful paper on coronavirus evolution. What do u do when the writing is so bad u can't understand the science?\"\n",
            "b\"wine corona virus' ? An epidemic at cb beach weekend?\"\n",
            "b\"nts to let the coronavirus know that its not you, its me. We can't go on like this. You will meet someone amazing -- I just know it.\"\n",
            "b'ino-virus, corona-virus, echo-virus, paramyxo-virus og coxsackie-virus. Alt om den forkj\\xc3\\xb8lte kroppen p\\xc3\\xa5 P1 n\\xc3\\xa5.'\n",
            "b'expected Link Between Coronavirus Replication And Protein Secretion In Infected Cells http://s3nt.com/cm6'\n",
            "b'w Coronavirus Found in Beluga Whale http://s3nt.com/a43'\n",
            "b'rse the germinator, that thought it not robbery to infest me with their deadly human coronavirus... I wish I could find the culprit!'\n",
            "b'cesito nueva m\\xc3\\xb9sica, mis 2 ultimos archivos subidos al itunes fueron los audios de mis clases sobre coronavirus y newcastle...'\n",
            "b'idence for an RNA virus proofreading machine:replication infidelity of coronavirus exonuclease mutants http://bit.ly/gK8W2p'\n",
            "b'erroMutt probably! I should have recognized the taste of coronavirus....'\n",
            "b'ronavirus Puppies Survival: Coronavirus Puppies Survival requires quick action and knowledge to save your pet.... http://bit.ly/gfRtlT'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cbgEgkH_w31F",
        "colab_type": "text"
      },
      "source": [
        "# Now apply the model you have trained on the scraped data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZs6Us8xw31G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        },
        "outputId": "e5bcc749-ba8b-4af9-b401-118eea597094"
      },
      "source": [
        "TestTweets[\"Tweets\"] = TestTweets[\"Tweets\"].apply(normalize_text)\n",
        "TestTweets[\"Tweets\"] = TestTweets[\"Tweets\"].apply(stemming_text)\n",
        "TestTweets[\"Tweets\"] = TestTweets[\"Tweets\"].apply(lemm_text)\n",
        "\n",
        "TestTweets"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tweets</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>b wait for page printout on coronaviru for cla...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>b wait for page printout on coronaviru for cla...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>b ishi no not yet vet last yr say coz she wa f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>b rvousli await further test result from the v...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>b ok like she might hav a good fight chanc of ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>b st get a call from the vet ella ha a viral i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>b nine coronaviru s gene and use therefor n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>b oyaleagl see our coronaviru db http lin cr gq</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>b scuss coronaviru sar in virolog class right now</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>b view an aw paper on coronaviru evolut what d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>b wine corona viru an epidem at cb beach weekend</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>b nt to let the coronaviru know that it not yo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>b ino viru corona viru echo viru paramyxo viru...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>b expect link between coronaviru replic and pr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>b w coronaviru find in beluga whale http s nt ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>b rse the germin that think it not robberi to ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>b cesito nueva m xc xb sica mi ultimo archivo ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>b idenc for an rna viru proofread machin repli...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>b erromutt probabl i should have recogn the ta...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>b ronaviru puppi surviv coronaviru puppi survi...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               Tweets\n",
              "0   b wait for page printout on coronaviru for cla...\n",
              "1   b wait for page printout on coronaviru for cla...\n",
              "2   b ishi no not yet vet last yr say coz she wa f...\n",
              "3   b rvousli await further test result from the v...\n",
              "4   b ok like she might hav a good fight chanc of ...\n",
              "5   b st get a call from the vet ella ha a viral i...\n",
              "6         b nine coronaviru s gene and use therefor n\n",
              "7     b oyaleagl see our coronaviru db http lin cr gq\n",
              "8   b scuss coronaviru sar in virolog class right now\n",
              "9   b view an aw paper on coronaviru evolut what d...\n",
              "10   b wine corona viru an epidem at cb beach weekend\n",
              "11  b nt to let the coronaviru know that it not yo...\n",
              "12  b ino viru corona viru echo viru paramyxo viru...\n",
              "13  b expect link between coronaviru replic and pr...\n",
              "14  b w coronaviru find in beluga whale http s nt ...\n",
              "15  b rse the germin that think it not robberi to ...\n",
              "16  b cesito nueva m xc xb sica mi ultimo archivo ...\n",
              "17  b idenc for an rna viru proofread machin repli...\n",
              "18  b erromutt probabl i should have recogn the ta...\n",
              "19  b ronaviru puppi surviv coronaviru puppi survi..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lIed9DxylVA9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "outputId": "66e28e63-7fed-4d60-d8b8-f37379bca55f"
      },
      "source": [
        "testtweets = vectorizer.transform(TestTweets[\"Tweets\"])\n",
        "\n",
        "testtweets = pd.DataFrame(\n",
        "    testtweets.astype(np.int32).toarray(), columns=vectorizer.get_feature_names())\n",
        "testtweets.head()"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>abl</th>\n",
              "      <th>absolut</th>\n",
              "      <th>abt</th>\n",
              "      <th>ac</th>\n",
              "      <th>accept</th>\n",
              "      <th>access</th>\n",
              "      <th>accid</th>\n",
              "      <th>account</th>\n",
              "      <th>ace</th>\n",
              "      <th>ach</th>\n",
              "      <th>act</th>\n",
              "      <th>action</th>\n",
              "      <th>activ</th>\n",
              "      <th>actual</th>\n",
              "      <th>ad</th>\n",
              "      <th>adam</th>\n",
              "      <th>add</th>\n",
              "      <th>addict</th>\n",
              "      <th>address</th>\n",
              "      <th>admit</th>\n",
              "      <th>ador</th>\n",
              "      <th>adventur</th>\n",
              "      <th>advic</th>\n",
              "      <th>afford</th>\n",
              "      <th>afraid</th>\n",
              "      <th>afternoon</th>\n",
              "      <th>age</th>\n",
              "      <th>ago</th>\n",
              "      <th>agre</th>\n",
              "      <th>ah</th>\n",
              "      <th>aha</th>\n",
              "      <th>ahaha</th>\n",
              "      <th>ahead</th>\n",
              "      <th>ahh</th>\n",
              "      <th>ahhh</th>\n",
              "      <th>ahhhh</th>\n",
              "      <th>aim</th>\n",
              "      <th>ain</th>\n",
              "      <th>aint</th>\n",
              "      <th>air</th>\n",
              "      <th>...</th>\n",
              "      <th>wouldn</th>\n",
              "      <th>wouldnt</th>\n",
              "      <th>wow</th>\n",
              "      <th>wrap</th>\n",
              "      <th>write</th>\n",
              "      <th>wrong</th>\n",
              "      <th>wtf</th>\n",
              "      <th>www</th>\n",
              "      <th>xbox</th>\n",
              "      <th>xd</th>\n",
              "      <th>xo</th>\n",
              "      <th>xoxo</th>\n",
              "      <th>xx</th>\n",
              "      <th>xxx</th>\n",
              "      <th>xxxx</th>\n",
              "      <th>ya</th>\n",
              "      <th>yah</th>\n",
              "      <th>yall</th>\n",
              "      <th>yard</th>\n",
              "      <th>yay</th>\n",
              "      <th>ye</th>\n",
              "      <th>yea</th>\n",
              "      <th>yeah</th>\n",
              "      <th>year</th>\n",
              "      <th>yeh</th>\n",
              "      <th>yell</th>\n",
              "      <th>yep</th>\n",
              "      <th>yesterday</th>\n",
              "      <th>yey</th>\n",
              "      <th>yfrog</th>\n",
              "      <th>yo</th>\n",
              "      <th>york</th>\n",
              "      <th>young</th>\n",
              "      <th>youtub</th>\n",
              "      <th>youu</th>\n",
              "      <th>yr</th>\n",
              "      <th>yu</th>\n",
              "      <th>yum</th>\n",
              "      <th>yummi</th>\n",
              "      <th>yup</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 2000 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   abl  absolut  abt  ac  accept  access  ...  youu  yr  yu  yum  yummi  yup\n",
              "0    0        0    0   0       0       0  ...     0   0   0    0      0    0\n",
              "1    0        0    0   0       0       0  ...     0   0   0    0      0    0\n",
              "2    0        0    0   0       0       0  ...     0   0   0    0      0    0\n",
              "3    0        0    0   0       0       0  ...     0   0   0    0      0    0\n",
              "4    0        0    0   0       0       0  ...     0   0   0    0      0    0\n",
              "\n",
              "[5 rows x 2000 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l3jaCyFwn_SK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "33011b0d-ba37-41ce-a191-fec3ffd66af2"
      },
      "source": [
        "y_pred = classifier.predict(testtweets)\n",
        "y_pred"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GckeTTA9w31J",
        "colab_type": "text"
      },
      "source": [
        "# Let's make some good looking charts \n",
        "\n",
        "use your favorite plotting library to plot the sentiment aggregation of the tweets you have gathered."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iv_v-jszw31K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5FujrXrew31O",
        "colab_type": "text"
      },
      "source": [
        "# Good job ! \n",
        "\n",
        "<center><img src=\"https://media.giphy.com/media/YRuFixSNWFVcXaxpmX/giphy.gif\"></center>\n",
        "\n",
        "# Now publish the notebook and show the world your work !"
      ]
    }
  ]
}